{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"xvSGDbExff_I"},"source":["# **Homework 7 - Bert (Question Answering)**\n","\n","If you have any questions, feel free to email us at ntu-ml-2023spring-ta@googlegroups.com\n","\n","\n","\n","Slide:    [Link](https://docs.google.com/presentation/d/15lGUmT8NpLGtoxRllRWCJyQEjhR1Idcei63YHsDckPE/edit#slide=id.g21fff4e9af6_0_13)　Kaggle: [Link](https://www.kaggle.com/competitions/ml2023spring-hw7/host/sandbox-submissions)　Data: [Link](https://drive.google.com/file/d/1YU9KZFhQqW92Lw9nNtuUPg0-8uyxluZ7/view?usp=sharing)\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NYAHsHNbzdKm"},"source":["# Prerequisites"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TevOvhC03m0h"},"source":["## Install packages\n","\n","Documentation for the toolkit: \n","*   https://huggingface.co/transformers/\n","*   https://huggingface.co/docs/accelerate/index\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T17:35:35.949574Z","iopub.status.busy":"2023-05-08T17:35:35.948357Z"},"id":"tbxWFX_jpDom","outputId":"d0d30026-5ead-4091-959b-237bd4dfd92a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers==4.26.1\n","  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.26.1) (0.13.2)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.26.1) (23.0)\n","Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.26.1) (4.11.4)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.26.1) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.26.1) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.26.1) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.26.1) (2021.11.10)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.26.1) (2.28.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.26.1) (1.21.6)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.26.1) (3.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1) (4.4.0)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.26.1) (3.11.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.26.1) (2022.12.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.26.1) (2.1.1)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.26.1) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.26.1) (1.26.14)\n","^C\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0mCollecting accelerate==0.16.0\n","  Downloading accelerate-0.16.0-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from accelerate==0.16.0) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from accelerate==0.16.0) (1.21.6)\n","Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from accelerate==0.16.0) (1.13.0)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from accelerate==0.16.0) (23.0)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from accelerate==0.16.0) (5.9.3)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4.0->accelerate==0.16.0) (4.4.0)\n","Installing collected packages: accelerate\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 0.12.0\n","    Uninstalling accelerate-0.12.0:\n","      Successfully uninstalled accelerate-0.12.0\n"]}],"source":["# You are allowed to change version of transformers or use other toolkits\n","!pip install transformers==4.26.1\n","!pip install accelerate==0.16.0"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"XapBp31gytyD"},"source":["# Kaggle (Fine-tuning)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"WGOr_eS3wJJf"},"source":["## Task description\n","- Chinese Extractive Question Answering\n","  - Input: Paragraph + Question\n","  - Output: Answer\n","\n","- Objective: Learn how to fine tune a pretrained model on downstream task using transformers\n","\n","- Todo\n","    - Fine tune a pretrained chinese BERT model\n","    - Change hyperparameters (e.g. doc_stride)\n","    - Apply linear learning rate decay\n","    - Try other pretrained models\n","    - Improve preprocessing\n","    - Improve postprocessing\n","- Training tips\n","    - Automatic mixed precision\n","    - Gradient accumulation\n","    - Ensemble\n","\n","- Estimated training time (tesla t4 with automatic mixed precision enabled)\n","    - Simple: 8mins\n","    - Medium: 8mins\n","    - Strong: 25mins\n","    - Boss: 2hrs\n","  "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8dKM4yCh4LI_"},"source":["## Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WOTHHtWJoahe","trusted":true},"outputs":[],"source":["import json\n","import numpy as np\n","import random\n","import torch\n","from torch.utils.data import DataLoader, Dataset \n","from transformers import AdamW, BertForQuestionAnswering, BertTokenizerFast, get_linear_schedule_with_warmup\n","\n","from tqdm.auto import tqdm\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Fix random seed for reproducibility\n","def same_seeds(seed):\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True\n","same_seeds(42)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2YgXHuVLp_6j"},"source":["## Install Fengshenbang-LM\n","\n","\n","\n","\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#REF: https://github.com/IDEA-CCNL/Fengshenbang-LM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xyBCYGjAp3ym","outputId":"c791b4be-ad21-4e28-9494-6bc515b55ceb","trusted":true},"outputs":[],"source":["!git clone https://github.com/IDEA-CCNL/Fengshenbang-LM.git\n","%cd Fengshenbang-LM\n","!pip install --editable ./"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Edit modeling_ubert.py by my code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mQDJLsRRsmDD","trusted":true},"outputs":[],"source":["# replace the modeling_ubert.py\n","# EX: !cp your_code_flie /kaggle/working/Fengshenbang-LM/fengshen/models/ubert/modeling_ubert.py\n","!cp /kaggle/input/ubert-for-t4x2/modeling_ubert.py /kaggle/working/Fengshenbang-LM/fengshen/models/ubert/modeling_ubert.py"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"3Td-GTmk5OW4"},"source":["## Read Data\n","\n","- Training set: 26918 QA pairs\n","- Dev set: 2863  QA pairs\n","- Test set: 3524  QA pairs\n","\n","- {train/dev/test}_questions:\t\n","  - List of dicts with the following keys:\n","   - id (int)\n","   - paragraph_id (int)\n","   - question_text (string)\n","   - answer_text (string)\n","   - answer_start (int)\n","   - answer_end (int)\n","- {train/dev/test}_paragraphs: \n","  - List of strings\n","  - paragraph_ids in questions correspond to indexs in paragraphs\n","  - A paragraph may be used by several questions "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NvX7hlepogvu","trusted":true},"outputs":[],"source":["def read_data(file):\n","    with open(file, 'r', encoding=\"utf-8\") as reader:\n","        data = json.load(reader)\n","    return data[\"questions\"], data[\"paragraphs\"]\n","\n","# Change the path of the dataset\n","train_questions, train_paragraphs = read_data(\"/kaggle/input/2023-ml-hw7-question-answering/hw7_train.json\")\n","dev_questions, dev_paragraphs = read_data(\"/kaggle/input/2023-ml-hw7-question-answering/hw7_dev.json\")\n","test_questions, test_paragraphs = read_data(\"/kaggle/input/2023-ml-hw7-question-answering/hw7_test.json\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uGGXgjI-2MUF","trusted":true},"outputs":[],"source":["ct = 0\n","checker = False\n","ll = []\n","for i in range(len(dev_questions)):\n","    checker = False\n","    for j in range(len(train_questions)):\n","        if(dev_questions[i][\"question_text\"] == train_questions[j][\"question_text\"]):\n","            checker = True\n","            ct+=1\n","    if not checker:\n","        ll.append(i)\n","\n","dev_questions2 = []\n","for i in ll:\n","    dev_questions2.append(dev_questions[i])\n","dev_questions = dev_questions2"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9cT4X-r6Qicz"},"source":["## Train_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GMTFoPVONEVd","trusted":true},"outputs":[],"source":["train_data = []\n","for i in range(len(train_questions)):\n","    data0 = {}\n","    entity0 = {}\n","    data0[\"task_type\"] = \"抽取任务\"\n","    data0[\"subtask_type\"] = \"抽取式阅读理解\"\n","    data0[\"text\"] = train_paragraphs[train_questions[i]['paragraph_id']]\n","    entity0[\"entity_type\"] = train_questions[i]['question_text']\n","    entity0[\"label\"] = 0\n","    entity0[\"entity_list\"] = [{\n","        \"entity_name\": train_questions[i]['answer_text'],\n","        \"entity_idx\": [\n","            [train_questions[i]['answer_start'], train_questions[i]['answer_end']]\n","        ]\n","    }]\n","    data0[\"choices\"] = [entity0]\n","    data0[\"id\"] = i\n","    train_data.append(data0)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"EpzTcIfYQl-D"},"source":["## Dev_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ystCr9NpQgvH","trusted":true},"outputs":[],"source":["dev_data = []\n","for i in range(len(dev_questions)):\n","    data0 = {}\n","    entity0 = {}\n","    data0[\"task_type\"] = \"抽取任务\"\n","    data0[\"subtask_type\"] = \"抽取式阅读理解\"\n","    data0[\"text\"] = dev_paragraphs[dev_questions[i]['paragraph_id']]\n","    entity0[\"entity_type\"] = dev_questions[i]['question_text']\n","    entity0[\"label\"] = 0\n","    entity0[\"entity_list\"] = [{\n","        \"entity_name\": dev_questions[i]['answer_text'],\n","        \"entity_idx\": [\n","             [dev_questions[i]['answer_start'], dev_questions[i]['answer_end']]\n","        ]\n","    }]\n","    data0[\"choices\"] = [entity0]\n","    data0[\"id\"] = i\n","    dev_data.append(data0)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"i1kS_G06RDpM"},"source":["## Test_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HGF_0BM6RFtA","trusted":true},"outputs":[],"source":["test_data = []\n","for i in range(len(test_questions)):\n","    data0 = {}\n","    entity0 = {}\n","    data0[\"task_type\"] = \"抽取任务\"\n","    data0[\"subtask_type\"] = \"抽取式阅读理解\"\n","    data0[\"text\"] = test_paragraphs[test_questions[i]['paragraph_id']]\n","    entity0[\"entity_type\"] = test_questions[i]['question_text']\n","    entity0[\"label\"] = 0\n","    entity0[\"entity_list\"] = []\n","    data0[\"choices\"] = [entity0]\n","    data0[\"id\"] = i\n","    test_data.append(data0)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"rzHQit6eMnKG"},"source":["## Main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yHOu4OnreuP8","outputId":"3d88abe0-fdf4-46b7-db9f-f5f2db5a5cd7","trusted":true},"outputs":[],"source":["!pip install pytorch-lightning==1.9.0\n","import pytorch_lightning as pl\n","print(pl.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#REF: https://github.com/IDEA-CCNL/Fengshenbang-LM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LL-TQvKzZ7jX","trusted":true},"outputs":[],"source":["class args:\n","    pretrained_model_path = 'IDEA-CCNL/Erlangshen-Ubert-330M-Chinese'      #预训练模型的路径，默认\n","    load_checkpoints_path = \"\"    #加载模型的路径，如果你finetune完，想加载模型进行预测可以传入这个参数\n","    batchsize = 1                  #批次大小, 默认 8\n","    monitor = \"train_span_acc\"             #保存模型需要监控的变量，例如我们可监控 val_span_acc\n","    checkpoint_path = \"./checkpoint\"           #模型保存的路径, 默认 ./checkpoint\n","    save_top_k = 3                 #最多保存几个模型, 默认 3\n","    every_n_train_steps = 100       #多少步保存一次模型, 默认 100\n","    learning_rate = 2e-5             #学习率, 默认 2e-5\n","    weight_decay = 0.1\n","    warmup  = 0.01                    #预热的概率, 默认 0.01\n","    default_root_dir = \"/kaggle/working/\"           #模型日子默认输出路径\n","    gradient_clip_val = 0.25          #梯度截断， 默认 0.25\n","    accelerator='gpu'\n","    devices=1                        #gpu 的数量\n","    check_val_every_n_epoch = 1     #多少次验证一次， 默认 100\n","    max_epochs = 2                 #多少个 epochs， 默认 5\n","    max_length = 512                 #句子最大长度， 默认 512\n","    num_labels = 10                 #训练每条样本最多取多少个label，超过则进行随机采样负样本， 默认 10'''\n","    mode = \"min\"\n","    save_weights_only = True\n","    filename = 'model-{epoch:02d}-{train_loss:.4f}'\n","    threshold = 0\n","    precision = 16\n","    accumulate_grad_batches = 8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bv4IFca4rf97","outputId":"6aaa8466-2dd1-4211-9b02-9e3a997a9147","trusted":true},"outputs":[],"source":["import argparse\n","from fengshen import UbertPipelines\n","\n","model = UbertPipelines(args)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"kMmdLOKBMsdE"},"source":["## Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KebvI83Zevt-","trusted":true},"outputs":[],"source":["result = model.predict(test_data)\n","result_post = []\n","ct = 0\n","ct1 = 0\n","ct2 = 0\n","for i in (result):\n","    result_post.append([i[\"choices\"][0][\"entity_list\"][0][\"entity_name\"],i[\"choices\"][0][\"entity_list\"][0][\"score\"]])\n","print(len(result_post))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Download result_model1 for the process later"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["result_file = \"result_model1.csv\"\n","%cd /kaggle/working/\n","with open(result_file, 'w') as f:\n","    f.write(\"ID,Answer,Score\\n\")\n","    for i, test_question in enumerate(test_questions):\n","    # Replace commas in answers with empty strings (since csv is separated by comma)\n","    # Answers in kaggle are processed in the same way\n","        f.write(f\"{test_question['id']},{result_post[i][0].replace(',','')},{result_post[i][1]}\\n\")\n","\n","print(f\"Completed! Result_raw is in {result_file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U5scNKC9xz0C","trusted":true},"outputs":[],"source":["result_file = \"result.csv\"\n","%cd /kaggle/working/\n","with open(result_file, 'w') as f:\n","    f.write(\"ID,Answer\\n\")\n","    for i, test_question in enumerate(test_questions):\n","    # Replace commas in answers with empty strings (since csv is separated by comma)\n","    # Answers in kaggle are processed in the same way\n","        f.write(f\"{test_question['id']},{result_post[i][0].replace(',','')}\\n\")\n","\n","print(f\"Completed! Result is in {result_file}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}

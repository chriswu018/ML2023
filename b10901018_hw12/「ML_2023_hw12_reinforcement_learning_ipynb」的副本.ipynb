{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp30SB4bxeQb"
      },
      "source": [
        "# **Homework 12 - Reinforcement Learning**\n",
        "\n",
        "If you have any problem, e-mail us at mlta-2023-spring@googlegroups.com\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXsnCWPtWSNk"
      },
      "source": [
        "## Preliminary work\n",
        "\n",
        "First, we need to install all necessary packages.\n",
        "One of them, gym, builded by OpenAI, is a toolkit for developing Reinforcement Learning algorithm. Other packages are for visualization in colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e2bScpnkVbv",
        "outputId": "7bb8f283-61ce-4915-9084-34678cf7ac8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Waiting for headers] [W\u001b[0m\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:7 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,781 kB]\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,352 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,060 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,539 kB]\n",
            "Hit:15 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,359 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,282 kB]\n",
            "Fetched 13.7 MB in 2s (6,091 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "21 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  freeglut3 libfontenc1 libpython2-stdlib libxfont2 libxkbfile1 python2\n",
            "  python2-minimal x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "Suggested packages:\n",
            "  python-tk python-numpy libgle3 python2-doc\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 libfontenc1 libpython2-stdlib libxfont2 libxkbfile1 python-opengl\n",
            "  python2 python2-minimal x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 14 newly installed, 0 to remove and 21 not upgraded.\n",
            "Need to get 8,318 kB of archives.\n",
            "After this operation, 18.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2-minimal amd64 2.7.17-2ubuntu4 [27.5 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libpython2-stdlib amd64 2.7.17-2ubuntu4 [7,072 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2 amd64 2.7.17-2ubuntu4 [26.5 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libfontenc1 amd64 1:1.1.4-0ubuntu1 [14.0 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal/main amd64 libxfont2 amd64 1:2.0.3-1 [91.7 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 libxkbfile1 amd64 1:1.1.0-1 [65.3 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-opengl all 3.1.0+dfsg-2build1 [486 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal/main amd64 x11-xkb-utils amd64 7.7+5 [158 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu1 [573 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-utils amd64 1:7.7+6 [91.5 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 xserver-common all 2:1.20.13-1ubuntu1~20.04.8 [27.2 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 xvfb amd64 2:1.20.13-1ubuntu1~20.04.8 [780 kB]\n",
            "Fetched 8,318 kB in 3s (2,721 kB/s)\n",
            "Selecting previously unselected package python2-minimal.\n",
            "(Reading database ... 123069 files and directories currently installed.)\n",
            "Preparing to unpack .../python2-minimal_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking python2-minimal (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package libpython2-stdlib:amd64.\n",
            "Preparing to unpack .../libpython2-stdlib_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n",
            "Setting up python2-minimal (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package python2.\n",
            "(Reading database ... 123098 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python2_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking python2 (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "Preparing to unpack .../01-freeglut3_2.8.1-3_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-3) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../02-libfontenc1_1%3a1.1.4-0ubuntu1_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../03-libxfont2_1%3a2.0.3-1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.3-1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../04-libxkbfile1_1%3a1.1.0-1_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1) ...\n",
            "Selecting previously unselected package python-opengl.\n",
            "Preparing to unpack .../05-python-opengl_3.1.0+dfsg-2build1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-2build1) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../06-x11-xkb-utils_7.7+5_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../07-xfonts-encodings_1%3a1.0.5-0ubuntu1_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu1) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../08-xfonts-utils_1%3a7.7+6_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../09-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../10-xserver-common_2%3a1.20.13-1ubuntu1~20.04.8_all.deb ...\n",
            "Unpacking xserver-common (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../11-xvfb_2%3a1.20.13-1ubuntu1~20.04.8_amd64.deb ...\n",
            "Unpacking xvfb (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-3) ...\n",
            "Setting up libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n",
            "Setting up python2 (2.7.17-2ubuntu4) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.3-1) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-2build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5) ...\n",
            "Setting up xfonts-utils (1:7.7+6) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Setting up xvfb (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting box2d==2.3.2\n",
            "  Downloading Box2D-2.3.2.tar.gz (427 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.9/427.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gym[box2d]==0.25.2 in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Collecting box2d-py\n",
            "  Downloading box2d-py-2.3.8.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.5/374.5 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
            "Requirement already satisfied: numpy==1.22.4 in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]==0.25.2) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]==0.25.2) (0.0.8)\n",
            "Collecting box2d-py\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pygame==2.1.0 (from gym[box2d]==0.25.2)\n",
            "  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gym[box2d]==0.25.2) (4.1.1)\n",
            "Building wheels for collected packages: box2d, box2d-py\n",
            "  Building wheel for box2d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d: filename=Box2D-2.3.2-cp310-cp310-linux_x86_64.whl size=2830184 sha256=54e7194728c866b39bfdc5fadcb440d0e7821bae76a9b8d58bf429bdbbb3afd6\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/cb/be/e663f3ce9aba6580611c0febaf7cd3cf7603f87047de2a52f9\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2812139 sha256=aadb7cfde228d79e45bf84f9751e107b3d1f695e6b93765a6f8a6ead4bccbab1\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d box2d-py\n",
            "Installing collected packages: pyvirtualdisplay, box2d-py, box2d, pygame\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.3.0\n",
            "    Uninstalling pygame-2.3.0:\n",
            "      Successfully uninstalled pygame-2.3.0\n",
            "Successfully installed box2d-2.3.2 box2d-py-2.3.5 pygame-2.1.0 pyvirtualdisplay-3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: box2d==2.3.2 in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Collecting box2d-kengz\n",
            "  Downloading Box2D-kengz-2.3.3.tar.gz (425 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.4/425.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: box2d-kengz\n",
            "  Building wheel for box2d-kengz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-kengz: filename=Box2D_kengz-2.3.3-cp310-cp310-linux_x86_64.whl size=2830652 sha256=16395b4b5f8d47c55e89ca3fc39b3deade5148f61bee98034608aa53e8260c36\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/a3/5f/6396406aa0163da86c2a8d28304a120b55cfa98363654d853b\n",
            "Successfully built box2d-kengz\n",
            "Installing collected packages: box2d-kengz\n",
            "Successfully installed box2d-kengz-2.3.3\n"
          ]
        }
      ],
      "source": [
        "!apt update\n",
        "!apt install python-opengl xvfb -y\n",
        "!pip install -q swig\n",
        "!pip install box2d==2.3.2 gym[box2d]==0.25.2 box2d-py pyvirtualdisplay tqdm numpy==1.22.4\n",
        "!pip install box2d==2.3.2 box2d-kengz\n",
        "!pip freeze > requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_-i3cdoYsks"
      },
      "source": [
        "\n",
        "Next, set up virtual display，and import all necessaary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nl2nREINDLiw"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from pyvirtualdisplay import Display\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaEJ8BUCpN9P"
      },
      "source": [
        "# Warning ! Do not revise random seed !!!\n",
        "# Your submission on JudgeBoi will not reproduce your result !!!\n",
        "Make your HW result to be reproducible.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fV9i8i2YkRbO"
      },
      "outputs": [],
      "source": [
        "seed = 2023 # Do not change this\n",
        "def fix(env, seed):\n",
        "  env.seed(seed)\n",
        "  env.action_space.seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "      torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He0XDx6bzjgC"
      },
      "source": [
        "Last, call gym and build an [Lunar Lander](https://gym.openai.com/envs/LunarLander-v2/) environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "N_4-xJcbBt09"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import gym\n",
        "import random\n",
        "env = gym.make('LunarLander-v2')\n",
        "fix(env, seed) # fix the environment Do not revise this !!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYBdh2CDF3SB"
      },
      "source": [
        "## D3QN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REF: https://github.com/DanielPalaio/LunarLander-v2_DeepRL/tree/main"
      ],
      "metadata": {
        "id": "kt7xqxM-MgvJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hDSNB7xLYih",
        "outputId": "32fac5ad-33f9-4fcf-bf39-43f0fe7afefa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "class ReplayBuffer():\n",
        "    def __init__(self, size, input_shape):\n",
        "        self.size = size\n",
        "        self.counter = 0\n",
        "        self.state_buffer = np.zeros((self.size, *input_shape), dtype=np.float32)\n",
        "        self.action_buffer = np.zeros(self.size, dtype=np.int32)\n",
        "        self.reward_buffer = np.zeros(self.size, dtype=np.float32)\n",
        "        self.new_state_buffer = np.zeros((self.size, *input_shape), dtype=np.float32)\n",
        "        self.terminal_buffer = np.zeros(self.size, dtype=np.bool_)\n",
        "\n",
        "    def store_tuples(self, state, action, reward, new_state, done):\n",
        "        idx = self.counter % self.size\n",
        "        self.state_buffer[idx] = state\n",
        "        self.action_buffer[idx] = action\n",
        "        self.reward_buffer[idx] = reward\n",
        "        self.new_state_buffer[idx] = new_state\n",
        "        self.terminal_buffer[idx] = done\n",
        "        self.counter += 1\n",
        "\n",
        "    def sample_buffer(self, batch_size):\n",
        "        max_buffer = min(self.counter, self.size)\n",
        "        batch = np.random.choice(max_buffer, batch_size, replace=False)\n",
        "        state_batch = self.state_buffer[batch]\n",
        "        action_batch = self.action_buffer[batch]\n",
        "        reward_batch = self.reward_buffer[batch]\n",
        "        new_state_batch = self.new_state_buffer[batch]\n",
        "        done_batch = self.terminal_buffer[batch]\n",
        "\n",
        "        return state_batch, action_batch, reward_batch, new_state_batch, done_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MRLeQubPF20d"
      },
      "outputs": [],
      "source": [
        "class DuelingDoubleDeepQNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Sequential(\n",
        "          nn.Linear(8, 128),\n",
        "          nn.ReLU(),\n",
        "        )\n",
        "        self.fc2 = nn.Sequential(\n",
        "          nn.Linear(128, 128),\n",
        "          nn.ReLU(),\n",
        "        )\n",
        "        self.V = nn.Linear(128, 1)\n",
        "        self.A = nn.Linear(128, 4)\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=0.00075)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = self.fc1(state)\n",
        "        x = self.fc2(x)\n",
        "        V = self.V(x)\n",
        "        A = self.A(x)\n",
        "        avg_A = torch.mean(A, dim=-1, keepdim=True)\n",
        "        Q = (V + (A - avg_A))\n",
        "\n",
        "        return Q, A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EGDy0Gt9MLWb"
      },
      "outputs": [],
      "source": [
        "class D3QNAgent():\n",
        "  def __init__(self, discount_factor=0.99, num_actions=4, epsilon=1.0, batch_size=64, input_dim=[8]):\n",
        "      self.action_space = [i for i in range(num_actions)]\n",
        "      self.discount_factor = discount_factor\n",
        "      self.epsilon = epsilon\n",
        "      self.batch_size = batch_size\n",
        "      self.epsilon_decay = 0.001\n",
        "      self.epsilon_final = 0.01\n",
        "      self.update_rate = 120\n",
        "      self.step_counter = 0\n",
        "      self.buffer = ReplayBuffer(100000, input_dim)\n",
        "      self.q_net = DuelingDoubleDeepQNetwork()\n",
        "      self.q_target_net = DuelingDoubleDeepQNetwork()\n",
        "      self.max_reward = 0\n",
        "\n",
        "  def store_tuple(self, state, action, reward, new_state, done):\n",
        "      self.buffer.store_tuples(state, action, reward, new_state, done)\n",
        "\n",
        "  def policy(self, observation):\n",
        "      if np.random.random() < self.epsilon:\n",
        "          action = np.random.choice(self.action_space)\n",
        "      else:\n",
        "          state = np.array([observation])\n",
        "          _, actions = self.q_net(torch.from_numpy(state))\n",
        "          action = np.argmax(actions.detach().numpy(), axis=1)[0]\n",
        "\n",
        "      return action\n",
        "  def train(self):\n",
        "    if self.buffer.counter < self.batch_size:\n",
        "        return\n",
        "    if self.step_counter % self.update_rate == 0:\n",
        "        for q_target_params, q_params in zip(self.q_target_net.parameters(), self.q_net.parameters()):\n",
        "            q_target_params.data.copy_(q_params)\n",
        "\n",
        "    self.q_net.train()\n",
        "    states, actions, rewards, next_states, terminals = self.buffer.sample_buffer(self.batch_size)\n",
        "    batch_idx = torch.arange(self.batch_size, dtype=torch.long)\n",
        "    states_tensor = torch.tensor(states, dtype=torch.float)\n",
        "    actions_tensor = torch.tensor(actions, dtype=torch.long)\n",
        "    rewards_tensor = torch.tensor(rewards, dtype=torch.float)\n",
        "    next_states_tensor = torch.tensor(next_states, dtype=torch.float)\n",
        "    terminals_tensor = torch.tensor(terminals)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        q_, _ = self.q_target_net.forward(next_states_tensor)\n",
        "        q2, _ = self.q_net.forward(next_states_tensor)\n",
        "        max_actions = torch.argmax(q2, dim=-1)\n",
        "        q_[terminals_tensor] = 0.0\n",
        "        target = rewards_tensor + self.discount_factor * q_[batch_idx, max_actions]\n",
        "    q, _ = self.q_net.forward(states_tensor)\n",
        "\n",
        "    loss = F.mse_loss(q[batch_idx, actions_tensor], target.detach())\n",
        "    self.q_net.optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    self.q_net.optimizer.step()\n",
        "\n",
        "    self.epsilon = self.epsilon - self.epsilon_decay if self.epsilon > self.epsilon_final else self.epsilon_final\n",
        "    self.step_counter += 1\n",
        "\n",
        "  def test_try(self):\n",
        "    fix(env, seed)\n",
        "    self.q_net.eval()  # set the network into evaluation mode\n",
        "    NUM_OF_TEST = 5 # Do not revise this !!!\n",
        "    test_total_reward = []\n",
        "    action_list = []\n",
        "    for i in range(NUM_OF_TEST):\n",
        "      actions = []\n",
        "      state = env.reset()\n",
        "\n",
        "      #img = plt.imshow(env.render(mode='rgb_array'))\n",
        "\n",
        "      total_reward = 0\n",
        "\n",
        "      done = False\n",
        "      while not done:\n",
        "          action = self.policy(state)\n",
        "          actions.append(action)\n",
        "          state, reward, done, _ = env.step(action)\n",
        "\n",
        "          total_reward += reward\n",
        "\n",
        "          #img.set_data(env.render(mode='rgb_array'))\n",
        "          #display.display(plt.gcf())\n",
        "          #display.clear_output(wait=True)\n",
        "\n",
        "      #print(total_reward)\n",
        "      test_total_reward.append(total_reward)\n",
        "\n",
        "      action_list.append(actions) # save the result of testing\n",
        "\n",
        "    #print(np.mean(test_total_reward))\n",
        "    if np.mean(test_total_reward) > self.max_reward:\n",
        "      self.max_reward = np.mean(test_total_reward)\n",
        "      print('new record:', self.max_reward)\n",
        "      distribution = {}\n",
        "      for actions in action_list:\n",
        "        for action in actions:\n",
        "          if action not in distribution.keys():\n",
        "            distribution[action] = 1\n",
        "          else:\n",
        "            distribution[action] += 1\n",
        "      print(distribution)\n",
        "\n",
        "      PATH = \"Action_List.npy\" # Can be modified into the name or path you want\n",
        "      np.save(PATH ,np.array(action_list))\n",
        "    else:\n",
        "      print(np.mean(test_total_reward))\n",
        "\n",
        "\n",
        "  def train_model(self, env, num_episodes):\n",
        "    scores, episodes, avg_scores, obj = [], [], [], []\n",
        "    goal = 200\n",
        "    f = 0\n",
        "    txt = open(\"saved_networks.txt\", \"w\")\n",
        "\n",
        "    for i in range(num_episodes):\n",
        "        done = False\n",
        "        score = 0.0\n",
        "        state = env.reset()\n",
        "        while not done:\n",
        "            action = self.policy(state)\n",
        "            new_state, reward, done, _ = env.step(action)\n",
        "            score += reward\n",
        "            self.store_tuple(state, action, reward, new_state, done)\n",
        "            state = new_state\n",
        "            self.train()\n",
        "        scores.append(score)\n",
        "        obj.append(goal)\n",
        "        episodes.append(i)\n",
        "        avg_score = np.mean(scores[-100:])\n",
        "        avg_scores.append(avg_score)\n",
        "        print(\"Episode {0}/{1}, Score: {2} ({3}), AVG Score: {4}\".format(i, num_episodes, score, self.epsilon, avg_score))\n",
        "        if avg_score >= 180.0 and score >= 230:\n",
        "            self.test_try()\n",
        "    plt.plot(avg_scores)\n",
        "    plt.title(\"Average Rewards\")\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3rbBlIjNpYM",
        "outputId": "a9d0a404-c302-4a33-97f6-2d43d3746ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0/800, Score: -100.78185180717264 (0.973), AVG Score: -100.78185180717264\n",
            "Episode 1/800, Score: -265.0908979523888 (0.8999999999999999), AVG Score: -182.93637487978071\n",
            "Episode 2/800, Score: -87.11924857016923 (0.8159999999999998), AVG Score: -150.99733277657688\n",
            "Episode 3/800, Score: -248.67310463223433 (0.6949999999999997), AVG Score: -175.41627574049124\n",
            "Episode 4/800, Score: -484.6653833796269 (0.5439999999999996), AVG Score: -237.2660972683184\n",
            "Episode 5/800, Score: -449.213579209247 (0.4289999999999995), AVG Score: -272.59067759180647\n",
            "Episode 6/800, Score: -111.70910277690714 (0.2989999999999994), AVG Score: -249.60759547539232\n",
            "Episode 7/800, Score: -297.588531905625 (0.14399999999999924), AVG Score: -255.60521252917138\n",
            "Episode 8/800, Score: -448.54353326855374 (0.01), AVG Score: -277.0428037224361\n",
            "Episode 9/800, Score: -464.3633629798325 (0.01), AVG Score: -295.7748596481757\n",
            "Episode 10/800, Score: -160.04142351569968 (0.01), AVG Score: -283.43545636340514\n",
            "Episode 11/800, Score: -246.28926149807748 (0.01), AVG Score: -280.33994012462784\n",
            "Episode 12/800, Score: -17.09829233458548 (0.01), AVG Score: -260.0905826023169\n",
            "Episode 13/800, Score: -51.90569975514538 (0.01), AVG Score: -245.2202338275189\n",
            "Episode 14/800, Score: -88.38657332732578 (0.01), AVG Score: -234.76465646083938\n",
            "Episode 15/800, Score: -160.71305403529033 (0.01), AVG Score: -230.1364313092426\n",
            "Episode 16/800, Score: -94.43765502528305 (0.01), AVG Score: -222.15415035136263\n",
            "Episode 17/800, Score: -53.13914856776661 (0.01), AVG Score: -212.76442803005176\n",
            "Episode 18/800, Score: 4.24227871595302 (0.01), AVG Score: -201.34302241184096\n",
            "Episode 19/800, Score: -139.00930333317683 (0.01), AVG Score: -198.22633645790776\n",
            "Episode 20/800, Score: -163.08875935654996 (0.01), AVG Score: -196.55311850070024\n",
            "Episode 21/800, Score: -147.47719638577394 (0.01), AVG Score: -194.3223947682036\n",
            "Episode 22/800, Score: -116.2189568721362 (0.01), AVG Score: -190.9265931205485\n",
            "Episode 23/800, Score: -265.66516515298736 (0.01), AVG Score: -194.04070028856677\n",
            "Episode 24/800, Score: -148.00212749306178 (0.01), AVG Score: -192.19915737674654\n",
            "Episode 25/800, Score: -82.15221159828761 (0.01), AVG Score: -187.96658253911352\n",
            "Episode 26/800, Score: -119.87324033537064 (0.01), AVG Score: -185.44460690193787\n",
            "Episode 27/800, Score: -207.0696035878635 (0.01), AVG Score: -186.2169282121495\n",
            "Episode 28/800, Score: -29.367949315376052 (0.01), AVG Score: -180.80834273295042\n",
            "Episode 29/800, Score: -50.592097880728794 (0.01), AVG Score: -176.46780123787636\n",
            "Episode 30/800, Score: -28.767123521365647 (0.01), AVG Score: -171.70326324702117\n",
            "Episode 31/800, Score: -82.2973164624807 (0.01), AVG Score: -168.9093274100043\n",
            "Episode 32/800, Score: -136.46214116968605 (0.01), AVG Score: -167.92607934211586\n",
            "Episode 33/800, Score: -170.98318314410204 (0.01), AVG Score: -168.01599415982136\n",
            "Episode 34/800, Score: -71.08173828007104 (0.01), AVG Score: -165.2464439918285\n",
            "Episode 35/800, Score: -253.41619891132802 (0.01), AVG Score: -167.6956038507035\n",
            "Episode 36/800, Score: -64.12814431606367 (0.01), AVG Score: -164.89648332274024\n",
            "Episode 37/800, Score: -59.267394467473615 (0.01), AVG Score: -162.11677045812795\n",
            "Episode 38/800, Score: -101.06425942006709 (0.01), AVG Score: -160.55132145715203\n",
            "Episode 39/800, Score: -31.735066021229116 (0.01), AVG Score: -157.33091507125397\n",
            "Episode 40/800, Score: -75.0575260809489 (0.01), AVG Score: -155.3242470471002\n",
            "Episode 41/800, Score: -98.32354024652109 (0.01), AVG Score: -153.9670873613721\n",
            "Episode 42/800, Score: -142.40736889468937 (0.01), AVG Score: -153.69825669935622\n",
            "Episode 43/800, Score: -31.455542451179195 (0.01), AVG Score: -150.92001319371582\n",
            "Episode 44/800, Score: -2.2667548144452905 (0.01), AVG Score: -147.61660745195425\n",
            "Episode 45/800, Score: -41.86837045471797 (0.01), AVG Score: -145.31773273462304\n",
            "Episode 46/800, Score: -43.123057131616974 (0.01), AVG Score: -143.14337793455908\n",
            "Episode 47/800, Score: -45.18050598970125 (0.01), AVG Score: -141.1024847690412\n",
            "Episode 48/800, Score: -38.51193022698464 (0.01), AVG Score: -139.00879998246864\n",
            "Episode 49/800, Score: -15.446875724023057 (0.01), AVG Score: -136.53756149729972\n",
            "Episode 50/800, Score: -35.37685497602753 (0.01), AVG Score: -134.55401823217676\n",
            "Episode 51/800, Score: 3.1536894329556118 (0.01), AVG Score: -131.90579308477035\n",
            "Episode 52/800, Score: -34.01586513619466 (0.01), AVG Score: -130.0588133121557\n",
            "Episode 53/800, Score: -72.75721760031405 (0.01), AVG Score: -128.9976726508253\n",
            "Episode 54/800, Score: -52.016044803303274 (0.01), AVG Score: -127.59800668996127\n",
            "Episode 55/800, Score: -73.93348926014019 (0.01), AVG Score: -126.63971173585732\n",
            "Episode 56/800, Score: -31.491092114398082 (0.01), AVG Score: -124.97043770741067\n",
            "Episode 57/800, Score: -48.74639132377749 (0.01), AVG Score: -123.65623001114112\n",
            "Episode 58/800, Score: -91.24161889079325 (0.01), AVG Score: -123.10682982266066\n",
            "Episode 59/800, Score: -79.68620257794684 (0.01), AVG Score: -122.38315270191542\n",
            "Episode 60/800, Score: -5.694769816749602 (0.01), AVG Score: -120.47022839232254\n",
            "Episode 61/800, Score: -15.600307808529944 (0.01), AVG Score: -118.77877806032588\n",
            "Episode 62/800, Score: -3.6705511781501095 (0.01), AVG Score: -116.9516633479104\n",
            "Episode 63/800, Score: 1.725374458433403 (0.01), AVG Score: -115.09733463218627\n",
            "Episode 64/800, Score: -63.6654462759325 (0.01), AVG Score: -114.30607481132083\n",
            "Episode 65/800, Score: -70.6699403999809 (0.01), AVG Score: -113.64492125963386\n"
          ]
        }
      ],
      "source": [
        "env = gym.make(\"LunarLander-v2\")\n",
        "spec = gym.spec(\"LunarLander-v2\")\n",
        "\n",
        "num_episodes = 800\n",
        "\n",
        "d3qn_agent = D3QNAgent(discount_factor=0.99, num_actions=4, epsilon=1.0, batch_size=64, input_dim=[8])\n",
        "\n",
        "d3qn_agent.train_model(env, num_episodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qIubdRd7NhJ3",
        "outputId": "5c315674-d262-49c1-a053-68b32ee12b95"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7d5cf28a-9e1f-4b45-9ccc-7a8d36e148b5\", \"Action_List.npy\", 31128)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"Action_List.npy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUBtYXG2eaqf"
      },
      "source": [
        "## Reference\n",
        "\n",
        "Below are some useful tips for you to get high score.\n",
        "\n",
        "- [DRL Lecture 1: Policy Gradient (Review)](https://youtu.be/z95ZYgPgXOY)\n",
        "- [ML Lecture 23-3: Reinforcement Learning (including Q-learning) start at 30:00](https://youtu.be/2-JNBzCq77c?t=1800)\n",
        "- [Lecture 7: Policy Gradient, David Silver](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/pg.pdf)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}